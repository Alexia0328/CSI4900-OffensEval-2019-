{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSI4900 TASK2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoutyJnPWRHB",
        "outputId": "9358ff55-fa5d-4cfc-ab4e-4321e5fbb50c"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/Colab Notebooks/CSI 4900\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['testset-levelb.tsv',\n",
              " 'labels-levelb.csv',\n",
              " 'CSI4900_subtask2.ipynb',\n",
              " 'CSI4900 TASK1.py',\n",
              " 'labels-levela.csv',\n",
              " 'olid-annotation.txt',\n",
              " 'testset-levela.tsv',\n",
              " 'olid-training-v1.0.tsv',\n",
              " 'RESULT1.PNG',\n",
              " 'OverFitting.PNG',\n",
              " '.ipynb_checkpoints',\n",
              " 'output_SVM_learning.csv',\n",
              " 'output_Bayes_learning.csv',\n",
              " 'output_RandomForest_learning.csv',\n",
              " 'CSI4900_TASK1.ipynb',\n",
              " 'output_Bayes_learning_B.csv',\n",
              " 'output_SVM_learning_B.csv',\n",
              " 'output_RandomForest_learning_B.csv',\n",
              " 'CSI4900 TASK2.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1pTYwFRZPMr"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from collections import Counter\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "label_to_number_b = {'UNT':0,'TIN':1}\n",
        "\n",
        "def clean_data(tweet):\n",
        "    splitted_tweet = tweet.lower().split()\n",
        "    clean_tweet = []\n",
        "    previous_word = None\n",
        "    user_count = 0\n",
        "    for word in splitted_tweet:\n",
        "        #if word not in spacy_stopwords:\n",
        "        word = re.sub(\"[#@]\",\"\",word)\n",
        "        word = re.sub(\"!\",\" !\",word)\n",
        "        word = re.sub(\"[?]\",\" ?\",word)\n",
        "        if(word == \"@USER\"):\n",
        "          pass\n",
        "        if(word == \"user\"):\n",
        "          user_count += 1\n",
        "        if(word == \"user\" and previous_word == \"user\"):\n",
        "          pass\n",
        "        else:\n",
        "          clean_tweet.append(word)\n",
        "        previous_word = word\n",
        "    return \" \".join(clean_tweet), user_count\n",
        "    \n",
        "\n",
        "#Deal with the dataset\n",
        "def read(testfiletsv):\n",
        "    plt.figure(figsize = (12,4))\n",
        "    plt.subplot(132)\n",
        "    a=pd.read_csv(testfiletsv, sep='\\t',)\n",
        "    cat_b = Counter(a[\"subtask_b\"])\n",
        "    x = cat_b.keys()\n",
        "    x1 = []\n",
        "    for i in x:\n",
        "      if(isinstance(i,str)):\n",
        "        x1.append(i)\n",
        "    print(list(cat_b.values()))\n",
        "    plt.bar(x1, [list(cat_b.values())[0],list(cat_b.values())[1]])\n",
        "    plt.xticks(range(len(cat_b)), label_to_number_b)\n",
        "    plt.title(\"Distribition of labels in subtask B\");\n",
        "    #since the distribution is not equal,we just choose 4000 from both sample\n",
        "    dfUNT=a[a[\"subtask_b\"] == \"UNT\"].sample(n=500, random_state=3)\n",
        "    dfTIN = a[a[\"subtask_b\"] == \"TIN\"].sample(n=500, random_state=2)\n",
        "    #To prevent undersampling or Oversampling, we choose equal size of results\n",
        "    dfPartial = dfUNT.append(dfTIN)\n",
        "    return dfPartial\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw3Nkl0Mafp6"
      },
      "source": [
        "#First Method,Let us try Bays_learning method first\n",
        "def learning(dfPartial):  \n",
        "    train_reviews, test_reviews, train_tags, test_tags = train_test_split(dfPartial[\"tweet\"],dfPartial[\"subtask_b\"],test_size=0.1, random_state=3,             \n",
        "                                                          stratify=dfPartial[\"subtask_b\"])\n",
        "    #we splite the training and testing datasets\n",
        "\n",
        "    train_tags = train_tags.to_numpy()\n",
        "    train_reviews = train_reviews.to_numpy()\n",
        "    test_tags = test_tags.to_numpy()\n",
        "    test_reviews = test_reviews.to_numpy()\n",
        "    #convertion and normalization deal with data\n",
        "\n",
        "    count_vect = CountVectorizer()\n",
        "    train_counts = count_vect.fit_transform(train_reviews)\n",
        "    negTrain=0;\n",
        "    posTrain=0;\n",
        "    posTest=0;\n",
        "    negTest=0;\n",
        "    trainSize = 900;\n",
        "    testSize = 100;\n",
        "    #Training process\n",
        "    for i in range(trainSize):\n",
        "        if (train_tags[i] == \"UNT\"):\n",
        "            posTrain+=1\n",
        "        if (train_tags[i] == \"TIN\"):\n",
        "            negTrain+=1  \n",
        "    for i in range(testSize):\n",
        "        if (test_tags[i] == \"UNT\"):\n",
        "            posTest+=1\n",
        "        if (test_tags[i] == \"TIN\"):\n",
        "            negTest+=1;\n",
        "    return(train_counts, train_tags,count_vect)  \n",
        "\n",
        "def Bayes_learning_result(train_counts, train_tags,count_vect,b):\n",
        "    sentence=b['tweet']\n",
        "    test_reviews_counts = count_vect.transform(sentence)\n",
        "    clf = MultinomialNB().fit(train_counts, train_tags)  \n",
        "    test_reviews_counts = count_vect.transform(sentence)\n",
        "    # Predict the results\n",
        "    prediction = clf.predict(test_reviews_counts)\n",
        "    # Print the first ten predictions\n",
        "    result=[]\n",
        "    for idnum,docTest, categoryTest in zip(b['id'],b['tweet'], prediction):   \n",
        "        #print('%r => %s\\n' % (docTest, categoryTest))\n",
        "        result.append([idnum,docTest, categoryTest])\n",
        "    return(result)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "pYF9XiXyazCL",
        "outputId": "d04b2ddd-b51b-48c1-d477-8e25703dbe89"
      },
      "source": [
        "a=read('olid-training-v1.0.tsv')\n",
        "for i in a[\"tweet\"]:\n",
        "  a[\"tweet\"][i]=clean_data(i)\n",
        "train_counts, train_tags,count_vect=learning(a)\n",
        "b=pd.read_csv('testset-levelb.tsv', delimiter='\\t',)\n",
        "result=Bayes_learning_result(train_counts, train_tags,count_vect,b)\n",
        "Bayes_learning_final=pd.DataFrame(result, columns=['id','tweet','task2'])\n",
        "print(Bayes_learning_final)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[524, 3876, 8840]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "        id                                              tweet task2\n",
            "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   TIN\n",
            "1    60133  #NoPasaran: Unity demo to oppose the far-right...   TIN\n",
            "2    83681           . . . What the fuck did he do this time?   UNT\n",
            "3    65507  @USER Do you get the feeling he is kissing @US...   TIN\n",
            "4    12588                        @USER Nigga ware da hits at   UNT\n",
            "..     ...                                                ...   ...\n",
            "235  22569  #Antifa are mentally unstable cowards, pretend...   TIN\n",
            "236  48938  @USER @USER And Browning looked like dog shit ...   UNT\n",
            "237  41438                All two of them taste like ass. URL   UNT\n",
            "238  73439  #DespicableDems lie again about rifles. Dem Di...   TIN\n",
            "239  67018  3 people just unfollowed me for talking about ...   UNT\n",
            "\n",
            "[240 rows x 3 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tfVH_SvKVTE"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "def  Randomforest_learning(train_counts, train_tags,count_vect,b):\n",
        "    sentence=b['tweet']\n",
        "    test_reviews_counts = count_vect.transform(sentence)\n",
        "    classifier = RandomForestClassifier(max_depth=800, min_samples_split=5)\n",
        "    params = {'n_estimators': [n for n in range(50,200,50)], 'criterion':['gini','entropy'], }\n",
        "    classifier = GridSearchCV(classifier, params, cv=3, n_jobs=4)\n",
        "    classifier.fit(train_counts, train_tags)\n",
        "    # Predict the results\n",
        "    prediction = classifier.predict(test_reviews_counts)\n",
        "    # Print the first ten predictions\n",
        "    result=[]\n",
        "    for idnum,docTest, categoryTest in zip(b['id'],b['tweet'], prediction):   \n",
        "        #print('%r => %s\\n' % (docTest, categoryTest))\n",
        "        result.append([idnum,docTest, categoryTest])\n",
        "    return(result)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "428W83y7Ka53",
        "outputId": "0b3a8f78-01c6-4468-8d47-e794851f213e"
      },
      "source": [
        "train_counts, train_tags,count_vect=learning(a)\n",
        "b=pd.read_csv('testset-levelb.tsv', delimiter='\\t',)\n",
        "result=Randomforest_learning(train_counts, train_tags,count_vect,b)\n",
        "Randomforest_learning_final=pd.DataFrame(result, columns=['id','tweet','task2'])\n",
        "print(Randomforest_learning_final)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id                                              tweet task2\n",
            "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   TIN\n",
            "1    60133  #NoPasaran: Unity demo to oppose the far-right...   TIN\n",
            "2    83681           . . . What the fuck did he do this time?   UNT\n",
            "3    65507  @USER Do you get the feeling he is kissing @US...   TIN\n",
            "4    12588                        @USER Nigga ware da hits at   UNT\n",
            "..     ...                                                ...   ...\n",
            "235  22569  #Antifa are mentally unstable cowards, pretend...   TIN\n",
            "236  48938  @USER @USER And Browning looked like dog shit ...   UNT\n",
            "237  41438                All two of them taste like ass. URL   UNT\n",
            "238  73439  #DespicableDems lie again about rifles. Dem Di...   TIN\n",
            "239  67018  3 people just unfollowed me for talking about ...   UNT\n",
            "\n",
            "[240 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5qEu5Fs8NTm"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "def  SVM(train_counts, train_tags,count_vect,b):\n",
        "    sentence=b['tweet']\n",
        "    test_reviews_counts = count_vect.transform(sentence)\n",
        "    classifier = SVC()\n",
        "    classifier = GridSearchCV(classifier, {'C':[0.001, 0.01, 0.1, 1, 10]}, cv=3, n_jobs=4)\n",
        "    classifier.fit(train_counts, train_tags)\n",
        "    # Predict the results\n",
        "    prediction = classifier.predict(test_reviews_counts)\n",
        "    # Print the first ten predictions\n",
        "    result=[]\n",
        "    for idnum,docTest, categoryTest in zip(b['id'],b['tweet'], prediction):   \n",
        "        #print('%r => %s\\n' % (docTest, categoryTest))\n",
        "        result.append([idnum,docTest, categoryTest])\n",
        "    return(result)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YSiCGOv91Y8",
        "outputId": "000e9e5d-7cd4-4646-b9d4-ea0d46e4a049"
      },
      "source": [
        "train_counts, train_tags,count_vect=learning(a)\n",
        "b=pd.read_csv('testset-levelb.tsv', delimiter='\\t',)\n",
        "result=SVM(train_counts, train_tags,count_vect,b)\n",
        "SVM_final=pd.DataFrame(result, columns=['id','tweet','task2'])\n",
        "print(SVM_final)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "        id                                              tweet task2\n",
            "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...   UNT\n",
            "1    60133  #NoPasaran: Unity demo to oppose the far-right...   TIN\n",
            "2    83681           . . . What the fuck did he do this time?   UNT\n",
            "3    65507  @USER Do you get the feeling he is kissing @US...   TIN\n",
            "4    12588                        @USER Nigga ware da hits at   UNT\n",
            "..     ...                                                ...   ...\n",
            "235  22569  #Antifa are mentally unstable cowards, pretend...   TIN\n",
            "236  48938  @USER @USER And Browning looked like dog shit ...   UNT\n",
            "237  41438                All two of them taste like ass. URL   UNT\n",
            "238  73439  #DespicableDems lie again about rifles. Dem Di...   UNT\n",
            "239  67018  3 people just unfollowed me for talking about ...   UNT\n",
            "\n",
            "[240 rows x 3 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDrjmtwd94ye",
        "outputId": "ae0ba9e9-dfbe-4059-f75c-c1090dc2f4a9"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "def result_compare():\n",
        "  b=pd.read_csv('labels-levelb.csv',names=[\"id\",\"task2\"])\n",
        "  print(\"Bays_Learning\")\n",
        "  print(classification_report(b[\"task2\"], Bayes_learning_final[\"task2\"],target_names=[\"UNT\",\"TIN\"]))\n",
        "  print(\"########################################################################################\")\n",
        "  Bayes_learning_final.to_csv(\"./output_Bayes_learning_B.csv\")  \n",
        "  print(\"RandomForest\")\n",
        "  print(classification_report(b[\"task2\"], Randomforest_learning_final[\"task2\"],target_names=[\"UNT\",\"TIN\"]))\n",
        "  print(\"########################################################################################\")\n",
        "  Randomforest_learning_final.to_csv(\"./output_RandomForest_learning_B.csv\") \n",
        "  print(\"SVM\")\n",
        "  print(classification_report(b[\"task2\"], SVM_final[\"task2\"],target_names=[\"UNT\",\"TIN\"]))\n",
        "  SVM_final.to_csv(\"./output_SVM_learning_B.csv\") \n",
        "result_compare()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bays_Learning\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         UNT       0.94      0.75      0.83       213\n",
            "         TIN       0.23      0.59      0.33        27\n",
            "\n",
            "    accuracy                           0.73       240\n",
            "   macro avg       0.58      0.67      0.58       240\n",
            "weighted avg       0.86      0.73      0.78       240\n",
            "\n",
            "########################################################################################\n",
            "RandomForest\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         UNT       0.95      0.69      0.80       213\n",
            "         TIN       0.23      0.74      0.35        27\n",
            "\n",
            "    accuracy                           0.69       240\n",
            "   macro avg       0.59      0.71      0.57       240\n",
            "weighted avg       0.87      0.69      0.75       240\n",
            "\n",
            "########################################################################################\n",
            "SVM\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         UNT       0.96      0.57      0.72       213\n",
            "         TIN       0.19      0.81      0.31        27\n",
            "\n",
            "    accuracy                           0.60       240\n",
            "   macro avg       0.58      0.69      0.52       240\n",
            "weighted avg       0.87      0.60      0.67       240\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}